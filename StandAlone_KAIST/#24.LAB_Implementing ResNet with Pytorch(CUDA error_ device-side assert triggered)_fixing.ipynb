{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"#24.LAB_Implementing ResNet with Pytorch(CUDA error: device-side assert triggered)_fixing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyONeEcs6vWvsHoehz9PQlAM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"80f3f1f828144e6792cefcc126f4fa29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d8132b651ee4e16b76031c39d60eb10","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_643edfe74b7a486a886ead23f9e0dc87","IPY_MODEL_06612e8815dc46718bf9628cc916af8b","IPY_MODEL_4101101cc89643ccae8218dbfac90c1d"]}},"3d8132b651ee4e16b76031c39d60eb10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"643edfe74b7a486a886ead23f9e0dc87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_07f086dcadb945958e3a83192cc005d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4b8753516484696bf96a3a93ce4e7f2"}},"06612e8815dc46718bf9628cc916af8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eca5d45caef347318cd35eabb06c05e5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2eb2990753049d9b172331d2fa493e4"}},"4101101cc89643ccae8218dbfac90c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9723de475ad6493db2f0f8cf04c02342","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:03&lt;00:00, 55492018.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e57a55734f8d4fc8a1ad72c3c5728655"}},"07f086dcadb945958e3a83192cc005d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f4b8753516484696bf96a3a93ce4e7f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eca5d45caef347318cd35eabb06c05e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2eb2990753049d9b172331d2fa493e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9723de475ad6493db2f0f8cf04c02342":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e57a55734f8d4fc8a1ad72c3c5728655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3gNuJfFLrLHA"},"source":["\n","\n","Lec6/Lab8_CIFAR100 with ResNet\n","\n","https://github.com/heartcored98/Standalone-DeepLearning/blob/master/Lec6/Lab8_CIFAR_100_with_ResNet.ipynb\n"]},{"cell_type":"code","metadata":{"id":"5mJe04wvrKT4"},"source":["!mkdir result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uh14WoXxpiXG"},"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kz7Y2yyarHe3"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import argparse\n","import numpy as np\n","import time\n","from copy import deepcopy # Add Deepcopy for args\n","import seaborn as sns \n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["80f3f1f828144e6792cefcc126f4fa29","3d8132b651ee4e16b76031c39d60eb10","643edfe74b7a486a886ead23f9e0dc87","06612e8815dc46718bf9628cc916af8b","4101101cc89643ccae8218dbfac90c1d","07f086dcadb945958e3a83192cc005d3","f4b8753516484696bf96a3a93ce4e7f2","eca5d45caef347318cd35eabb06c05e5","a2eb2990753049d9b172331d2fa493e4","9723de475ad6493db2f0f8cf04c02342","e57a55734f8d4fc8a1ad72c3c5728655"]},"id":"-CG-lmLxr4Wo","executionInfo":{"status":"ok","timestamp":1635319175050,"user_tz":-540,"elapsed":7811,"user":{"displayName":"MJ K","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05742109314629357515"}},"outputId":"5a9aed0b-ecc6-4865-9d29-d87558fd56c6"},"source":["# 1.Data Preparation: 기존 CIFAR-10 epdlxj wjwkd zhemdptj CIFAR-100으로 바꾸기만 하면 CIFAR-100을 사용할 수 있음\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n","trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n","\n","testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n","partition = {'train': trainset, 'val':valset, 'test':testset}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80f3f1f828144e6792cefcc126f4fa29","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-100-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","metadata":{"id":"F23IWj5nxpAz"},"source":["# 2.Model Architecture\n","# ResNet: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n","\n","# conv 3x3 and conv 1x1 functions\n","# pytorch Docs: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html?highlight=conv2d#torch.nn.Conv2d\n","# 항상 Docs를 보고 프레임워크와 이해도를 향상시킬 줄 알아야함\n","\n","# input tensor depth가 얼만지, activation이 몇개 있는지, 몇 개의 필터를 적용해서 output tensor를 뽑아 낼 것인지\n","# stride가 1일 경우 dimension이 유지가 됨, stride가 2을 사용하면 max-pooling 대신에 dimesion을 딱 절반으로 줄여주는 역할을 함\n","def conv3x3(in_planes, out_planes, stride=1):   # kernel_size = conv3x3 = 3\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, bias=False)\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSthmYe57ulZ"},"source":["# # 3.BasicBlock Module\n","# # BasicBlock: 하나의 residual block은 input x를 받아 3x3Conv, relu(Activation), 3x3Conv 원래의 identity x를 더해주는 형식\n","# # https://imgur.com/a/M9gZjWc\n","# class BasicBlock(nn.Module):    # 항상 nn.Moudule을 상속\n","#     expansion = 1\n","\n","#     # stride: dimension을 유지할 것인지, 절반으로 줄일 역할을 할 것인지     \n","#     def __init__(self, inplanes, planes, stride=1, downsample=None):    \n","#         super(BasicBlock, self).__init__()\n","#         self.conv1 = conv3x3(inplanes, planes, stride)\n","#         self.bn1 = nn.BatchNorm2d(planes)       # ResNet에서는 모든 Conv후에는 BatchNorm을 했기 때문에 추가, mm.BatchNorm2d(num_feature) --> depth=planes 수\n","#         self.relu = nn.ReLU(inplace=True)\n","#         self.conv2 = conv3x3(planes, planes)    # 첫 conv에서 정해진 depth를 유지해야하므로 conv2에서는 stride가 1이어야함\n","#         self.bn2 = nn.BatchNorm2d(planes)\n","#         self.downsample = downsample            # downsample: identity x를 더할 떄, dimension이 바꼈으면, 바뀐 경우에만 downsample을 적용\n","#         self.stride = stride\n","\n","#     def forward(self, x):\n","#         identity = x                            # 나중에 더하기 위해 초기 x 값을 저장\n","\n","#         out = self.conv1(x)\n","#         out = self.bn1(out)\n","#         out = self.relu(out)\n","\n","#         out = self.conv2(out)\n","#         out = self.bn2(out)\n","\n","#         if self.downsample is not None:         # downsample 기본 값이 None이라는 것은 dimension이 똑같다는 의미.\n","#             identity = self.downsample(x)\n","\n","#         out += identity\n","#         out = self.relu(out)\n","\n","#         return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqeAdAALklX_"},"source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n","        )\n","\n","        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","\n","        # projection mapping using 1x1conv\n","        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n","            )\n","\n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfSscS-wZ2cr"},"source":["# # 4.Bottleneck Module: 50개 이상의 layer를 가진 ResNet architecture에서 computatiional efficiency를 증가시키기 위해\n","# #                      3x3 convolution layer 앞뒤로 1x1 convolution layer를 추가한 Bottleneck module 구현하기\n","# #                      이 Bottlneck Module을 거치게 되면 depth가 4배 증가됨\n","# # https://imgur.com/a/HrpmJbU\n","# class Bottleneck(nn.Module):\n","#     expansion = 4\n","\n","#     def __init__(self, inplanes, planes, stride=1, downsample=None):\n","#         super(Bottleneck, self).__init__()\n","#         self.conv1 = conv1x1(inplanes, planes)\n","#         self.bn1 = nn.BatchNorm2d(planes)\n","#         self.conv2 = conv3x3(planes, planes, stride)\n","#         self.bn2 = nn.BatchNorm2d(planes)\n","#         self.conv3 = conv1x1(planes, planes * self.expansion)           # Paper에서 bottleneck layer를 거치게 되면 depth가 4배 증가시키도록 설정\n","#         self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","#         self.relu = nn.ReLU(inplace=True)\n","#         self.downsample = downsample\n","#         self.stride = stride\n","\n","#     def forward(self, x):\n","#         identity = x\n","\n","#         out = self.conv1(x)\n","#         out = self.bn1(out)\n","#         out = self.relu(out)\n","\n","#         out = self.conv2(out)\n","#         out = self.bn2(out)\n","#         out = self.relu(out)\n","\n","#         out = self.conv3(out)\n","#         out = self.bn3(out)\n","\n","#         if self.downsample is not None:\n","#             identity = self.downsample(x)\n","\n","#         out += identity\n","#         out = self.relu(out)\n","\n","#         return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNCWocs6lE4j"},"source":["class BottleNeck(nn.Module):\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        self.shortcut = nn.Sequential()\n","\n","        self.relu = nn.ReLU()\n","\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n","            )\n","            \n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXaUPJbNy8iB"},"source":["# # 5.ResNet Module: 적절한 Block type과 layer 수, 그리고 최종적으로 분류할 class 갯수를 받아 ResNet architecture 구현하기\n"," \n","# class ResNet(nn.Module):\n","#     def __init__(self, block, num_block, num_classes=1000, zero_init_residual=False):\n","#         super(ResNet, self).__init__()\n","#         self.inplanes = 64\n","#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","#         self.bn1 = nn.BatchNorm2d(64)\n","#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","#         self.layer1 = self._make_layer(block, 64, num_block[0])\n","#         self.layer2 = self._make_layer(block, 128, num_block[1], stride=2)\n","#         self.layer3 = self._make_layer(block, 256, num_block[2], stride=2)\n","#         self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n","#         self.fc = nn.Linear(512*block.expansion, num_classes)\n","\n","#         for m in self.modules():\n","#             if isinstance(m, nn,Conv2d):\n","#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","#             elif isinstance(m, nn.BatchNorm2d):\n","#                 nn.init.constant_(m.weight, 1)\n","#                 nn.init.constant_(m.bias, 0)\n","\n","#         # Zero-initialize the last BN in each residual branch,\n","#         # so that the residual branch starts with zeroes, and each residual block behaves like an identity.\n","#         # This improve the model by 0.2 ~ 0.3% according to paper\n","#         if zero_init_residual:\n","#             for m in self.module():\n","#                 if isinstance(m, Bottleneck):\n","#                     nn.init.constant_(m.bn3.weight, 0)\n","#                 elif isinstance(m, BasicBlock):\n","#                     nn.init.constant_(m.bn2.weight, 0)\n","\n","#     def _make_layer(self, block, out_channels, num_blocks, stride):\n","#         strides = [stride] + [1] * (num_blocks - 1)\n","#         layers = []\n","#         for stride in strides:\n","#             layers.append(block(self.in_channels, out_channels, stride))\n","#             self.in_channels = out_channels * block.expansion\n","\n","#         return nn.Sequential(*layers)\n","\n","#     # def _make_layer(self, block, planes, blocks, stride=1):\n","#     #     downsample = None\n","#     #     if stride != 1 or self.inplanes != planes * block.expansion:\n","#     #         downsample = nn.Sequential(conv1x1(self.inplanes, planes*block.expansion, stride), nn.BatchNorm2d(planes*block.expansion))\n","\n","#         layers = []\n","#         layers.appends = planes*block.expansion\n","#         self.inplanes = planes*block.expansion\n","#         for _ in range(1, blocks):\n","#             layersappend(block(self.inplanes, planes))\n","\n","#         return nn.Sequential(*layers)\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         x = self.bn1(x)\n","#         x = self.relu(x)\n","#         x = self.maxpool(x)\n","\n","#         x = self.layer1(x)\n","#         x = self.layer2(x)\n","#         x = self.layer3(x)\n","#         x = self.layer4(x)\n","\n","#         x = self.avgpool(x)\n","#         x = x.view(X.size(0), -1)\n","#         x = self.fc(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IK-gS_yh2uK"},"source":["class ResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=100, init_weights=True):\n","        super().__init__()\n","\n","        self.in_channels=64\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        )\n","\n","        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # weights inittialization\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride))\n","            self.in_channels = out_channels * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self,x):\n","        output = self.conv1(x)\n","        output = self.conv2_x(output)\n","        x = self.conv3_x(output)\n","        x = self.conv4_x(x)\n","        x = self.conv5_x(x)\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","    # define weight initialization function\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","def resnet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","def resnet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","def resnet50():\n","    return ResNet(BottleNeck, [3,4,6,3])\n","\n","def resnet101():\n","    return ResNet(BottleNeck, [3, 4, 23, 3])\n","\n","def resnet152():\n","    return ResNet(BottleNeck, [3, 8, 36, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiatfLC3Fni4"},"source":["# 6.Train, Validate, Test and Experiment\n","def train(net, partition, optimizer, criterion, args):\n","    trainloader = torch.utils.data.DataLoader(partition['train'], \n","                                              batch_size=args.train_batch_size, \n","                                              shuffle=True, num_workers=2)\n","    net.train()\n","\n","    correct = 0\n","    total = 0\n","    train_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        optimizer.zero_grad() # [21.01.05 오류 수정] 매 Epoch 마다 .zero_grad()가 실행되는 것을 매 iteration 마다 실행되도록 수정했습니다. \n","\n","        # get the inputs\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = net(inputs)\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    train_loss = train_loss / len(trainloader)\n","    train_acc = 100 * correct / total\n","    return net, train_loss, train_acc\n","\n","def validate(net, partition, criterion, args):\n","    valloader = torch.utils.data.DataLoader(partition['val'], \n","                                            batch_size=args.test_batch_size, \n","                                            shuffle=False, num_workers=2)\n","    net.eval()\n","\n","    correct = 0\n","    total = 0\n","    val_loss = 0 \n","    with torch.no_grad():\n","        for data in valloader:\n","            images, labels = data\n","            images = images.cuda()\n","            labels = labels.cuda()\n","            outputs = net(images)\n","\n","            loss = criterion(outputs, labels)\n","            \n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(valloader)\n","        val_acc = 100 * correct / total\n","    return val_loss, val_acc\n","\n","\n","def test(net, partition, args):\n","    testloader = torch.utils.data.DataLoader(partition['test'], \n","                                             batch_size=args.test_batch_size, \n","                                             shuffle=False, num_workers=2)\n","    net.eval()\n","    \n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images = images.cuda()\n","            labels = labels.cuda()\n","\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        test_acc = 100 * correct / total\n","    return test_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8e05xkw5F0UY"},"source":["def experiment(partition, args):\n","  \n","    net = ResNet(BottleNeck, args.num_block)\n","    net.cuda()\n","\n","    criterion = nn.CrossEntropyLoss()\n","    if args.optim == 'SGD':\n","        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'RMSprop':\n","        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'Adam':\n","        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n","    else:\n","        raise ValueError('In-valid optimizer choice')\n","    \n","    train_losses = []\n","    val_losses = []\n","    train_accs = []\n","    val_accs = []\n","        \n","    for epoch in range(args.epoch):  # loop over the dataset multiple times\n","        ts = time.time()\n","        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args)\n","        val_loss, val_acc = validate(net, partition, criterion, args)\n","        te = time.time()\n","        \n","        train_losses.append(train_loss)\n","        val_losses.append(val_loss)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        \n","        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n","        \n","    test_acc = test(net, partition, args)    \n","    \n","    result = {}\n","    result['train_losses'] = train_losses\n","    result['val_losses'] = val_losses\n","    result['train_accs'] = train_accs\n","    result['val_accs'] = val_accs\n","    result['train_acc'] = train_acc\n","    result['val_acc'] = val_acc\n","    result['test_acc'] = test_acc\n","    return vars(args), result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6pEL96YF2OM"},"source":["# 7.Manage Experiment Result\n","import hashlib\n","import json\n","from os import listdir\n","from os.path import isfile, join\n","import pandas as pd\n","\n","def save_exp_result(setting, result):\n","    exp_name = setting['exp_name']\n","    del setting['epoch']\n","    del setting['test_batch_size']\n","\n","    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n","    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n","    result.update(setting)\n","    with open(filename, 'w') as f:\n","        json.dump(result, f)\n","\n","    \n","def load_exp_result(exp_name):\n","    dir_path = './results'\n","    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n","    list_result = []\n","    for filename in filenames:\n","        if exp_name in filename:\n","            with open(join(dir_path, filename), 'r') as infile:\n","                results = json.load(infile)\n","                list_result.append(results)\n","    df = pd.DataFrame(list_result) # .drop(columns=[])\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqbKO-xuF7Gn"},"source":["# 8.Visualization Utility\n","def plot_acc(var1, var2, df):\n","\n","    fig, ax = plt.subplots(1, 3)\n","    fig.set_size_inches(15, 6)\n","    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n","\n","    sns.barplot(x=var1, y='train_acc', hue=var2, data=df, ax=ax[0])\n","    sns.barplot(x=var1, y='val_acc', hue=var2, data=df, ax=ax[1])\n","    sns.barplot(x=var1, y='test_acc', hue=var2, data=df, ax=ax[2])\n","    \n","    ax[0].set_title('Train Accuracy')\n","    ax[1].set_title('Validation Accuracy')\n","    ax[2].set_title('Test Accuracy')\n","    \n","def plot_loss_variation(var1, var2, df, **kwargs):\n","\n","    list_v1 = df[var1].unique()\n","    list_v2 = df[var2].unique()\n","    list_data = []\n","\n","    for value1 in list_v1:\n","        for value2 in list_v2:\n","            row = df.loc[df[var1]==value1]\n","            row = row.loc[df[var2]==value2]\n","\n","            train_losses = list(row.train_losses)[0]\n","            val_losses = list(row.val_losses)[0]\n","\n","            for epoch, train_loss in enumerate(train_losses):\n","                list_data.append({'type':'train', 'loss':train_loss, 'epoch':epoch, var1:value1, var2:value2})\n","            for epoch, val_loss in enumerate(val_losses):\n","                list_data.append({'type':'val', 'loss':val_loss, 'epoch':epoch, var1:value1, var2:value2})\n","\n","    df = pd.DataFrame(list_data)\n","    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n","    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n","    g.add_legend()\n","    g.fig.suptitle('Train loss vs Val loss')\n","    plt.subplots_adjust(top=0.89) # 만약 Title이 그래프랑 겹친다면 top 값을 조정해주면 됩니다! 함수 인자로 받으면 그래프마다 조절할 수 있겠죠?\n","    \n","def plot_acc_variation(var1, var2, df, **kwargs):\n","    list_v1 = df[var1].unique()\n","    list_v2 = df[var2].unique()\n","    list_data = []\n","\n","    for value1 in list_v1:\n","        for value2 in list_v2:\n","            row = df.loc[df[var1]==value1]\n","            row = row.loc[df[var2]==value2]\n","\n","            train_accs = list(row.train_accs)[0]\n","            val_accs = list(row.val_accs)[0]\n","            test_acc = list(row.test_acc)[0]\n","\n","            for epoch, train_acc in enumerate(train_accs):\n","                list_data.append({'type':'train', 'Acc':train_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n","            for epoch, val_acc in enumerate(val_accs):\n","                list_data.append({'type':'val', 'Acc':val_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n","\n","    df = pd.DataFrame(list_data)\n","    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n","    g = g.map(plt.plot, 'epoch', 'Acc', marker='.')\n","\n","    def show_acc(x, y, metric, **kwargs):\n","        plt.scatter(x, y, alpha=0.3, s=1)\n","        metric = \"Test Acc: {:1.3f}\".format(list(metric.values)[0])\n","        plt.text(0.05, 0.95, metric,  horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n","    g = g.map(show_acc, 'epoch', 'Acc', 'test_acc')\n","\n","    g.add_legend()\n","    g.fig.suptitle('Train Accuracy vs Val Accuracy')\n","    plt.subplots_adjust(top=0.89)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"yQGzmUU15zbZ","executionInfo":{"status":"error","timestamp":1635319696485,"user_tz":-540,"elapsed":241,"user":{"displayName":"MJ K","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05742109314629357515"}},"outputId":"d181952c-2325-4455-d301-361a3b6513fa"},"source":["# ====== Random Seed Initialization ====== #\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args(\"\")\n","args.exp_name = \"exp1_ResNet\"\n","\n","# ====== Model ====== #\n","## #21.Lab\n","# args.model_code = 'VGG11'\n","# args.in_channels = 3\n","# args.in_dim = 3072\n","# args.out_dim = 10\n","# # args.hid_dim = 100\n","# args.act = 'relu'\n","args.layers = 3072\n","args.num_block = [3, 4, 6, 3]\n","\n","# ====== Regularization ======= #\n","# args.dropout = 0.2\n","args.use_bn = True\n","args.l2 = 0.0015\n","args.epoch = 10\n","# args.use_xavier = True\n","\n","# ====== Optimizer & Training ====== #\n","args.optim = 'RMSprop' #'RMSprop' #SGD, RMSprop, ADAM...\n","args.lr = 0.0015\n","args.epoch = 10\n","\n","args.train_batch_size = 256     # updated       # 이거 돌렸을 때 처음에 에러나서 머가 잘못 됬는지 계속 찾았는데 다시 껏다 켜서 실행하니깐 다시 됨. 머지?\n","args.test_batch_size = 256\n","\n","# ====== Experiment Variable ====== #\n","name_var1 = 'optim'\n","name_var2 = 'lr'\n","list_var1 = [\"SGD\", \"Adam\"]\n","list_var2 = [0.01, 0.001]\n","\n","\n","for var1 in list_var1:\n","    for var2 in list_var2:\n","        setattr(args, name_var1, var1)\n","        setattr(args, name_var2, var2)\n","        print(args)\n","                \n","        setting, result = experiment(partition, deepcopy(args))\n","        save_exp_result(setting, result)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-1eb9b9c9d358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"noMUG6gQ9baf","executionInfo":{"status":"error","timestamp":1635319375923,"user_tz":-540,"elapsed":268,"user":{"displayName":"MJ K","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05742109314629357515"}},"outputId":"152137f0-5b70-4776-de28-806a5688e581"},"source":["var1 = 'layers'\n","var2 = 'lr'\n","df = load_exp_result('exp1_ResNet')\n","\n","plot_acc(var1, var2, df)\n","plot_loss_variation(var1, var2, df, sharey=False)\n","plot_acc_variation(var1, var2, df, margin_title=True, sharey=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-d0a291d492e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvar1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'layers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_exp_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exp1_ResNet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-1bc29cb1f520>\u001b[0m in \u001b[0;36mload_exp_result\u001b[0;34m(exp_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_exp_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./results'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'.json'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mlist_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results'"]}]},{"cell_type":"code","metadata":{"id":"FUWaGKPW913o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635316212108,"user_tz":-540,"elapsed":691,"user":{"displayName":"MJ K","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05742109314629357515"}},"outputId":"9b46401c-9301-4cc5-f1e6-a7bf8f99daf4"},"source":["!ls -al\n","!ls ./result"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 24\n","drwxr-xr-x 1 root root 4096 Oct 27 05:49 .\n","drwxr-xr-x 1 root root 4096 Oct 27 05:28 ..\n","drwxr-xr-x 4 root root 4096 Oct  8 13:44 .config\n","drwxr-xr-x 3 root root 4096 Oct 27 05:49 data\n","drwxr-xr-x 2 root root 4096 Oct 27 05:48 result\n","drwxr-xr-x 1 root root 4096 Oct  8 13:45 sample_data\n"]}]}]}